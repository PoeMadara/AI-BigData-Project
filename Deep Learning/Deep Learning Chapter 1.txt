Chapter 1 Introduction
Artificial Intelligence (AI) aims to create systems that mimic intelligent behavior. It encompasses a variety of methods, including techniques based on logic, search, and probabilistic reasoning. Machine learning is a branch of AI that learns to make decisions by fitting mathematical models to observational data. This field has developed rapidly in recent years and is now almost (though not entirely accurately) synonymous with AI.

Deep neural networks are a type of machine learning model, and the process of applying them to data is called deep learning. Currently, deep networks are among the most powerful and practical machine learning models, commonly used in everyday life. We often use Natural Language Processing (NLP) algorithms to translate text, Computer Vision systems to search for images of specific objects, or Speech Recognition interfaces to converse with digital assistants, all of which are practical applications of deep learning.

As the title of this book suggests, it aims to help beginners understand the fundamentals of deep learning. This book is neither heavily theoretical (no proofs) nor overly practical (almost no code). Its goal is to explain the core ideas of deep learning; after reading this book, readers should be able to apply deep learning in new contexts where no ready-made successful solutions exist.

Broadly speaking, machine learning methods are divided into three main categories: Supervised Learning, Unsupervised Learning, and Reinforcement Learning. Currently, the cutting-edge methods in all three categories rely on deep learning (see Figure 1.1). The opening chapter of this book introduces these three categories from a high-level perspective, and this categorization is also reflected in the structure of the book. Whether we like it or not, deep learning will change our world, and not all of these changes will be positive. Therefore, this chapter also briefly introduces the basic concepts of AI ethics. Finally, we offer some suggestions to help readers make the most of this book.

1.1 Supervised Learning
Supervised learning models establish a relationship between input data and output predictions. In the following sections, we will explore the input, output, the model itself, and what "training" a model means.

1.1.1 Regression and Classification Problems
Figure 1.2 shows examples of regression and classification problems. In each example, there is an input relevant to the real world (such as a sentence, an audio file, a picture, etc.), which is converted into a numerical vector. This vector is the input to the model. The model maps this input to an output vector, which is then converted back into a prediction with real-world significance. For now, we focus on the input and output and treat the model as a black box that accepts a numerical vector and outputs another numerical vector.

In Figure 1.2a, the model predicts house prices based on input features such as square footage and the number of bedrooms. This is a regression problem because the model returns a continuous value (not a category). In Figure 1.2b, the model takes the chemical structure of a molecule as input and predicts its melting and boiling points. This is a multivariate regression problem because multiple values are predicted.

In Figure 1.2c, the model receives a text string of restaurant reviews as input and predicts whether the review is positive or negative. This is a binary classification problem because the model tries to assign the input to one of two categories. The output vector contains the probabilities of the input belonging to each category. Figures 1.2d and 1.2e illustrate multi-class classification problems. Here, the model assigns the input to more than two categories. In the first example, the input is an audio file, and the model predicts the type of music it contains. In the second example, the input is an image, and the model predicts the objects in the image. In these examples, the model returns an N-dimensional vector containing the probabilities for each category.

1.1.2 Input
The types of input data in Figure 1.2 vary. In the house price prediction example, the input is a fixed-length vector containing values describing the property features. This is tabular data with no inherent structure; if we change the order of the input values and build a new model, the expected prediction results should not change.

On the other hand, in the restaurant review example, the input is a piece of text. This may vary in length depending on the number of words in the review, and the order of the input is important; for example, "My wife ate chicken" versus "The chicken ate my wife" have completely different meanings. The text must be encoded in numerical form before being fed to the model. Here, we use a fixed vocabulary of 10,000 words and simply concatenate the word indices.

In the music classification example, the input vector may be of fixed size (e.g., a 10-second audio clip), but its dimension is very high. Digital audio is typically sampled at 44.1 kHz and represented as 16-bit integers, so a 10-second audio clip contains 441,000 integers. Clearly, supervised learning models must handle large inputs. The input in the image classification example (concatenated RGB values for each pixel) is also very large and inherently two-dimensional; even if not adjacent in the input vector, two adjacent pixels are closely related.

Finally, consider the input to a model that predicts the melting and boiling points of molecules. A molecule may contain a different number and arrangement of atoms. In this case, the model needs to consider both the geometric structure and the constituent atoms of the molecule.

1.1.3 Machine Learning Models
So far, we have treated the machine learning model as a black box that accepts input vectors and returns output vectors. But what exactly is inside this black box? Consider a model that predicts a child's height based on age (see Figure 1.3). A machine learning model is essentially a mathematical function that maps input to output. In this example, the model could be a linear regression line fitting the data points, where the input is the child's age and the output is the predicted height.

A linear model like this is one of the simplest forms of a machine learning model. More complex models, such as neural networks, involve many more parameters and layers of calculations, but the core idea remains the same: they map inputs to outputs based on learned patterns in the data.

This section continues with detailed examples and further explanations of various types of machine learning models and their applications.

A linear model like this is one of the simplest forms of a machine learning model. More complex models, such as neural networks, involve many more parameters and layers of calculations, but the core idea remains the same: they map inputs to outputs based on learned patterns in the data.

For instance, consider a neural network trained to recognize handwritten digits (Figure 1.3). The input to the model is an image of a digit, and the output is the predicted digit. The neural network consists of multiple layers of neurons, each performing a series of weighted sums and nonlinear transformations. These layers learn to extract hierarchical features from the input data, progressively transforming the input image into a set of high-level features that can be used to make the final prediction.

1.1.4 Training a Model
Training a machine learning model involves adjusting its parameters so that it makes accurate predictions on the training data. This process typically involves defining a loss function, which measures the discrepancy between the model's predictions and the true values. The goal of training is to minimize this loss function.

In supervised learning, training data consists of input-output pairs, where the output is the ground truth label for the input. The model learns to make predictions by minimizing the loss function on this training data. This is often done using gradient descent, an optimization algorithm that iteratively adjusts the model's parameters to reduce the loss.

For example, in the height prediction model, the loss function could be the mean squared error between the predicted heights and the actual heights of the children in the training data. By minimizing this error, the model learns the relationship between age and height.

1.2 Unsupervised Learning
Unsupervised learning models find patterns or structures in the input data without using labeled outputs. These models are used for tasks such as clustering, dimensionality reduction, and anomaly detection.

1.2.1 Clustering
Clustering algorithms group similar data points into clusters. For example, a clustering algorithm could group customers based on their purchasing behavior, identifying segments of customers with similar preferences. The algorithm does this by optimizing a clustering criterion, such as minimizing the distance between data points within each cluster.

1.2.2 Dimensionality Reduction
Dimensionality reduction techniques reduce the number of features in the data while preserving important information. This is useful for visualizing high-dimensional data or reducing the computational complexity of machine learning models. Principal Component Analysis (PCA) is a common dimensionality reduction technique that transforms the data into a lower-dimensional space by finding the directions of maximum variance.

1.2.3 Anomaly Detection
Anomaly detection algorithms identify unusual or rare data points that differ significantly from the majority of the data. These algorithms are used in applications such as fraud detection and network security. For example, an anomaly detection model could identify fraudulent transactions by recognizing patterns that deviate from typical transaction behavior.

1.3 Reinforcement Learning
Reinforcement learning (RL) involves training an agent to make decisions by interacting with an environment. The agent receives feedback in the form of rewards or punishments based on its actions, and it learns to maximize the cumulative reward over time.

1.3.1 Markov Decision Processes
Reinforcement learning problems are often modeled as Markov Decision Processes (MDPs), which consist of states, actions, rewards, and transition probabilities. The agent learns a policy, which is a mapping from states to actions that maximizes the expected cumulative reward.

1.3.2 Q-Learning and Policy Gradients
Q-learning is a popular reinforcement learning algorithm that learns a value function, which estimates the expected cumulative reward for each state-action pair. The agent uses this value function to choose actions that maximize the expected reward. Policy gradient methods, on the other hand, directly optimize the policy by adjusting its parameters to increase the expected reward.

1.4 Ethics in Artificial Intelligence
The rapid advancement of AI and deep learning has raised important ethical considerations. These include issues related to privacy, bias, transparency, and the impact of AI on employment and society. It is crucial to develop AI systems that are fair, accountable, and transparent.

1.4.1 Bias and Fairness
AI systems can inadvertently learn biases present in the training data, leading to unfair or discriminatory outcomes. It is important to address these biases through careful data collection, algorithm design, and evaluation.

1.4.2 Transparency and Explainability
AI systems, particularly deep learning models, can be complex and opaque, making it difficult to understand how they make decisions. Enhancing the transparency and explainability of AI systems is essential for building trust and ensuring accountability.

1.5 Making the Most of This Book
To make the most of this book, readers are encouraged to actively engage with the material, experiment with the concepts, and explore additional resources. The book provides a high-level overview of deep learning, but deeper understanding comes from hands-on practice and continuous learning.

In summary, this chapter has introduced the key concepts of deep learning, including supervised learning, unsupervised learning, and reinforcement learning. It has also highlighted the importance of ethical considerations in AI. The following chapters will delve deeper into these topics, providing a comprehensive understanding of deep learning and its applications.

